// FractalOpponent as a depth-aware router around UnifiedMultiHeadTransformerLSTMCell + CombinatorialPathGate.
using TorchSharp;
using TorchSharp.Modules;
using static TorchSharp.torch;

public class FractalOpponent : nn.Module
{
    public int LastDepthChosen { get; set; } = 0;
    public bool DisableButterfly { get; set; } = false;
    public bool DisableDepth { get; set; } = false;
    public bool DisablePathGate { get; set; } = false;
    public int ForcedExpert { get; set; } = 0;
    private readonly Linear depthAnchorGate;

    private readonly Linear depthRamanujanHead;
    private readonly UnifiedMultiHeadTransformerLSTMCell cell;
    public readonly CombinatorialPathGate pathGate;
    private readonly Linear depthRouter; // logits over {0..maxDepth}
    private readonly ButterflyEffectGate butterflyGate;
    public readonly int hiddenSize;
    private readonly int maxDepth;
    public int LastWinningExpert { get; private set; } = -1;
    // Primary constructor: external unified cell
    public FractalOpponent(UnifiedMultiHeadTransformerLSTMCell cell, int hiddenSize, int maxDepth)
        : base("fractal_opponent_router")
    {
        butterflyGate = new ButterflyEffectGate(hiddenSize);
        this.cell = cell ?? throw new ArgumentNullException(nameof(cell));
        this.hiddenSize = hiddenSize;
        this.maxDepth = Math.Max(0, maxDepth);

        pathGate = new CombinatorialPathGate(hiddenSize: hiddenSize, basisCount: 4, depth: maxDepth);

        // depth router over discrete depths [0..maxDepth]
        depthRouter = nn.Linear(hiddenSize, maxDepth + 1);

        // NEW: Ramanujan head for depth [1,2H] -> [1,H]
        depthRamanujanHead = nn.Linear(hiddenSize * 2, hiddenSize);
        depthAnchorGate = nn.Linear(hiddenSize * 2, hiddenSize);
        RegisterComponents();

    }


    private void DebugFeedbackLoop(Tensor hCur, Tensor hNextRaw, int depth, float damping =1)
    {
        var signalMagnitude = hCur.abs().mean().ToSingle();
        var correctionMagnitude = (hNextRaw.abs().mean() * damping).ToSingle();

        // Das Verhältnis von Korrektur zu Signal
        float feedbackRatio = correctionMagnitude / (signalMagnitude + 1e-6f);

        string indent = new string(' ', depth * 2);
        Console.WriteLine($"{indent}[Depth {depth}] Feedback-Ratio: {feedbackRatio:P2} (Signal: {signalMagnitude:F4})");

        if (float.IsNaN(feedbackRatio) || feedbackRatio > 10.0f)
        {
            Console.WriteLine($"{indent} [!!!] CRITICAL: Feedback Loop Divergence at Depth {depth}");
        }
    }
    // Compatibility constructor: internal unified cell
    public FractalOpponent(int hiddenSize, int maxDepth)
        : this(new UnifiedMultiHeadTransformerLSTMCell(hiddenSize, hiddenSize, 4, 1), hiddenSize, maxDepth)
    {
        pathGate = new CombinatorialPathGate(hiddenSize: hiddenSize, basisCount: 4, depth: maxDepth);

        // depth router over discrete depths [0..maxDepth]
        depthRouter = nn.Linear(hiddenSize, maxDepth + 1);

        // Ramanujan head for depth
        depthRamanujanHead = nn.Linear(hiddenSize * 2, hiddenSize);

        // NEW: depth AnchorGate
        depthAnchorGate = nn.Linear(hiddenSize * 2, hiddenSize);

        RegisterComponents();

    }

    // core recursive logic: depth-aware routing
    // x: [H] or [B,inputSize], h,c: [B,H]

    public (Tensor output, Tensor h, Tensor c) forward(Tensor x, Tensor h, Tensor c, int depth = 0)
    {
        // === 1) Shallow pass ===
        var (shallowOut, hShallow, cShallow) = cell.forward_step(x, h, c);

        // === 2) Path Gate (patched) ===
        Tensor hPath;
        if (DisablePathGate)
        {
            // Skip routing entirely
            hPath = hShallow.alias();
            LastWinningExpert = -1;
        }
        else
        {
            hPath = pathGate.forward(hShallow);
            LastWinningExpert = pathGate.LastWinningExpert;
        }

        // === 3) Depth Decision (patched) ===
        int steps = 0;

        if (!DisableDepth)
        {
            using (var depthLogits = depthRouter.forward(hPath))
            using (var depthProbs = depthLogits.softmax(1))
            using (var depthIdx = depthProbs.argmax(1))
            {
                int chosenDepth = depthIdx.ToInt32();
                int remaining = Math.Max(0, maxDepth - depth);
                steps = Math.Min(chosenDepth, remaining);
            }
        }
        else
        {
            steps = 0; // disable recursion
        }

        if (steps <= 0)
        {
            return (shallowOut.alias(), hPath.alias(), cShallow.alias());
        }

        // === 4) Recursive refinement ===
        var hCur = hPath.alias();
        var cCur = cShallow.alias();
        var finalOut = shallowOut.alias();

        var depthStates = new List<Tensor>();
        depthStates.Add(hCur.alias());

        for (int i = 0; i < steps; i++)
        {
            float damping = (float)(1.0 / Math.Pow(depth + 1, 2));

            // === BUTTERFLY EFFECT GATE (patched) ===
            Tensor UpdateFn(Tensor hLocal)
            {
                var (_, hNextLocal, _) = forward(x, hLocal, cCur, depth + 1);
                return hNextLocal;
            }

            Tensor hNext;

            if (DisableButterfly)
            {
                // Skip butterfly stabilization
                hNext = UpdateFn(hCur);
            }
            else
            {
                hNext = butterflyGate.forward(hCur, UpdateFn, depth);
            }

            // Actual recursive call
            var (hRecursiveOut, hNextRaw, cNext) = forward(x, hCur, cCur, depth + 1);

            // Debugging
            if (DateTime.Now.Millisecond % 5000 == 0)
            {
                DebugFeedbackLoop(hCur, hNextRaw, depth, damping);
            }

            depthStates.Add(hNext.alias());

            // Cleanup
            hCur.Dispose();
            cCur.Dispose();
            finalOut.Dispose();
            hNextRaw.Dispose();

            // Update
            hCur = hNext;
            cCur = cNext;
            finalOut = hRecursiveOut;
        }

        // === 5) Ramanujan depth anchor ===
        var hDepthAnchor = MultiAgentFractalCore.RamanujanSum(depthStates.ToArray(), depthRamanujanHead);

        // === 6) Depth Anchor Gate ===
        var depthGateInput = torch.cat(new Tensor[] { hCur, hDepthAnchor }, dim: 1);
        var depthGateRaw = depthAnchorGate.forward(depthGateInput);
        var depthG = depthGateRaw.sigmoid();

        var hOut = depthG * hDepthAnchor + (1 - depthG) * hCur;

        return (finalOut, hOut, cCur);
    }
}
